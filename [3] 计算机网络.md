[TOC]

# 计算机网络

## Socket网络编程

### TCP

服务器：

1. 加载库--WSAStartup()
2. 创建套接字--socket()
3. 绑定ip和端口号--bind()
4. 监听--listen()
5. 等待连接--accept()
6. 接收数据--recv()
7. 发送数据--send()
8. 关闭套接字--closesocket()
9. 卸载库--WSACleanup()

客户端：

1. 加载库--WSAStartup()
2. 创建套接字--socket()
3. 建立连接--connect()
4. 接收数据--recv()
5. 发送数据--send()
6. 关闭套接字--closesocket()
7. 卸载库--WSACleanup()

### UDP

服务器：

1. 加载库--WSAStartup()
2. 创建套接字--socket()
3. 绑定ip和端口号--bind()
4. 接收数据--recvfrom（）
5. 发送数据--sendto()
6. 关闭套接字--closesocket()
7. 卸载库--WSACleanup()

客户端：

1. 加载库--WSAStartup()
2. 创建套接字--socket()
3. 接收数据--recvfrom（）
4. 发送数据--sendto()
5. 关闭套接字--closesocket()
6. 卸载库--WSACleanup()

## IO多路复用模型

### select

![image-20230503150025666](C:\Users\zj\AppData\Roaming\Typora\typora-user-images\image-20230503150025666.png)

执行流程：

1. 从用户空间拷贝fd_set（注册的事件集合）到内核空间。
2. 遍历所有fd文件，并将当前进程挂到每个fd的等待队列中，当某个fd文件设备收到消息后，会唤醒设备等待队列上睡眠的进程，那么当前进程就会被唤醒。
3. 如果遍历完所有的fd没有I/O事件，则当前进程进入睡眠，当有某个fd文件有I/O事件或当前进程睡眠超时后，当前进程重新唤醒再次遍历所有fd文件。

监听方式：

1. 阻塞监听：挂起，一直轮询监听（最后一个参数传空即可）。
2. 定时阻塞监听：可以设置监听固定时长，阻塞监听固定时间，到时间返回（设置时间结构体，传入即可）。
3. 非阻塞监听：轮询一次不管有没有事件都会返回（传时间结构体传timeout.seconds = 0或timeout.微妙 = 0）。

优点：

1. 兼容性较强，各平台都有select的实现。
2. select定时阻塞时间精度较高（支持微妙级别），适用于某些对时间有需求的环境。
3. 加入select使tcp模型单进程拥有一对多处理效果（实现简单，便于维护）。

缺点：

1. 采用fd_set作为监听集合，因为类型限制，最大只能监听1024个socket，适用于局域网。
2. select采用轮询方式监听IO事件，随着轮询数量的增长，IO处理效率呈线性下降（不能及时处理，系统开销增大）。
3. 没有将传入和传出分离，用户需要自己设置分离。
4. 只能反馈就绪数量，用户需要遍历socket数组查找就绪的socket，使用体验差，遍历判断开销大。
5. 工作时会产生大量无意义的拷贝开销，每次调用 select，都需要把监听集合从用户空间拷贝到内核空间，这个开销在监听集合很多时会很大，浪费系统资源。

### poll

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的。

优点：

1. 监听集合传入传出分离，不需要用户自行分离。
2. 突破了1024的数量限制（但本质问题在于轮询，没有解决根本问题）用户定义指定类型自定义长度的数组。
3. 能监听的事件种类较多。

缺点：

1. select的所有缺点。
2. 兼容性差。
3. 时间精度也差，只能毫秒级别和秒级别。

### epoll

epoll可以理解为event pool，不同与select、poll的轮询机制，epoll采用的是事件驱动机制，每个fd上有注册有回调函数，当网卡接收到数据时会回调该函数，同时将该fd的引用放入rdlist就绪列表中。
当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。

![image-20230503150904944](C:\Users\zj\AppData\Roaming\Typora\typora-user-images\image-20230503150904944.png)

监听和就绪过程（红黑树，有去重功能，重复自动丢弃），没有使用内核的IO设备等待队列（轮询），而是自定义监听队列，事件就绪后自定义监听队列给红黑树上的就绪节点发送通知，对应的节点执行call_back回调函数，节点会弹出到传出的就绪队列上（与传出的就绪数组是共享映射的关系）。

epoll事件的触发模式：

![image-20230503150955683](C:\Users\zj\AppData\Roaming\Typora\typora-user-images\image-20230503150955683.png)

执行流程：

1. 调用epoll_create()创建一个ep对象，即红黑树的根节点，返回一个文件句柄。
2. 调用epoll_ctl()向这个ep对象（红黑树）中添加、删除、修改感兴趣的事件。
3. 调用epoll_wait()等待，当有事件发生时网卡驱动会调用fd上注册的函数并将该fd添加到rdlist中，解除阻塞。

总结：

1. EPOLL支持的最大文件描述符上限是整个系统最大可打开的文件数目, 1G内存理论上最大创建10万个文件描述符。
2. 每个文件描述符上都有一个callback函数，当socket有事件发生时会回调这个函数将该fd的引用添加到就绪列表中，select和poll并不会明确指出是哪些文件描述符就绪，而epoll会。造成的区别就是，系统调用返回后，调用select和poll的程序需要遍历监听的整个文件描述符找到是谁处于就绪，而epoll则直接处理即可。
3. select、poll采用轮询的方式来检查文件描述符是否处于就绪态，而epoll采用回调机制。造成的结果就是，随着fd的增加，select和poll的效率会线性降低，而epoll不会受到太大影响，除非活跃的socket很多。

优点：

1. 真正意义上突破了监听数量的限制，主机能创建多少个socket，epoll都可以监听，并且不会有额外的开销。
2. 监听采用的是非轮询方式，回调方式，无论监听多少IO都不会有太大的系统开销。
3. 当事件就绪后不仅会返回就绪数量，还会返回就绪队列，用户直接遍历处理就绪队列即可拿到socket和就绪事件。
4. 没有重复拷贝的情况，所有监听的节点只会拷贝和挂载一次。

## TCP

### 头部格式 

<img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230534096.png" alt="TCP 头格式" style="zoom:50%;" />

### 三次握手

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png" alt="TCP 三次握手" style="zoom: 50%;" />

一开始，客户端和服务端都处于 `CLOSE` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态。

1. 客户端会随机初始化序号（`client_isn`），将此序号置于 TCP 首部的「序号」字段中，同时把 `SYN` 标志位置为 `1`，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 `SYN-SENT` 状态。
2. 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（`server_isn`），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `client_isn + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态。
3. 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次「确认应答号」字段填入 `server_isn + 1` ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 `ESTABLISHED` 状态。

服务端收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

#### 为什么是三次握手？不是两次、四次？

三次握手才可以阻止重复历史连接的初始化（主要原因）。

三次握手才可以同步双方的初始序列号。

三次握手才可以避免资源浪费。

1. 避免历史连接

   我们来看看 RFC 793 指出的 TCP 连接使用三次握手的首要原因：

   简单来说，三次握手的首要原因是为了防止旧的重复连接初始化造成混乱。

   我们考虑一个场景，客户端先发送了 SYN（seq = 90）报文，然后客户端宕机了，而且这个 SYN 报文还被网络阻塞了，服务端并没有收到，接着客户端重启后，又重新向服务端建立连接，发送了 SYN（seq = 100）报文（注意！不是重传 SYN，重传的 SYN 的序列号是一样的）。

   客户端连续发送多次 SYN（都是同一个四元组）建立连接的报文，在网络拥堵情况下：

   一个「旧 SYN 报文」比「最新的 SYN」 报文早到达了服务端，那么此时服务端就会回一个 `SYN + ACK` 报文给客户端，此报文中的确认号是 91（90+1）。

   客户端收到后，发现自己期望收到的确认号应该是 100 + 1，而不是 90 + 1，于是就会回 RST 报文。

   服务端收到 RST 报文后，就会释放连接。

   后续最新的 SYN 抵达了服务端后，客户端与服务端就可以正常的完成三次握手了。

   上述中的「旧 SYN 报文」称为历史连接，TCP 使用三次握手建立连接的最主要原因就是防止「历史连接」初始化了连接。

   **如果是两次握手连接，就无法阻止历史连接**，主要是因为**在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费**。

   在两次握手的情况下，服务端在收到 SYN 报文后，就进入 ESTABLISHED 状态，意味着这时可以给对方发送数据，但是客户端此时还没有进入 ESTABLISHED 状态，假设这次是历史连接，客户端判断到此次连接为历史连接，那么就会回 RST 报文来断开连接，而服务端在第一次握手的时候就进入 ESTABLISHED 状态，所以它可以发送数据的，但是它并不知道这个是历史连接，它只有在收到 RST 报文后，才会断开连接。

   如果采用两次握手建立 TCP 连接的场景下，服务端在向客户端发送数据前，并没有阻止掉历史连接，导致服务端建立了一个历史连接，又白白发送了数据，妥妥地浪费了服务端的资源。

   因此，**要解决这种现象，最好就是在服务端发送数据前，也就是建立连接之前，要阻止掉历史连接，这样就不会造成资源浪费，而要实现这个功能，就需要三次握手**。

   所以，**TCP 使用三次握手建立连接的最主要原因是防止「历史连接」初始化了连接。**

2. 同步双方初始序列号

   TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：

   接收方可以去除重复的数据；

   接收方可以根据数据包的序列号按序接收；

   可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；

   可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样一来一回，才能确保双方的初始序列号能被可靠的同步。

   四次握手其实也能够可靠的同步双方的初始化序号，但由于**第二步和第三步可以优化成一步**，所以就成了「三次握手」。

   而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。

3. 避免资源浪费

   如果只有「两次握手」，当客户端发生的 `SYN` 报文在网络中阻塞，客户端没有接收到 `ACK` 报文，就会重新发送 `SYN` ，**由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 `ACK` 报文，所以服务端每收到一个 `SYN` 就只能先主动建立一个连接**，这会造成什么情况呢？

   如果客户端发送的 `SYN` 报文在网络中阻塞了，重复发送多次 `SYN` 报文，那么服务端在收到请求后就会**建立多个冗余的无效链接，造成不必要的资源浪费。**

总结：TCP 建立连接时，通过三次握手**能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号**。序列号能够保证数据包不重复、不丢弃和按序传输。

不使用「两次握手」和「四次握手」的原因：

「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；

「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

###  四次挥手

<img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230614791.png" alt="客户端主动关闭连接 —— TCP 四次挥手" style="zoom:50%;" />

1. 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。

2. 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSE_WAIT` 状态。

   客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。

3. 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。

4. 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态

    服务端收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。

   客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

可以看到，每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。

这里一点需要注意是：**主动关闭连接的，才有 TIME_WAIT 状态。**

#### 为什么需要挥手四次

再来回顾下四次挥手双方发 `FIN` 包的过程，就能理解为什么需要四次了。

关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。

服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，因此是需要四次挥手。

但是**在特定情况下，四次挥手是可以变成三次挥手的**。

#### 为什么 TIME_WAIT 等待的时间是 2MSL？

`MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 `TTL` 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。

MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。

**TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了**。

TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以**一来一回需要等待 2 倍的时间**。

比如，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 `FIN` 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL。

可以看到 **2MSL时长** 这其实是相当于**至少允许报文丢失一次**。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。

为什么不是 4 或者 8 MSL 的时长呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。

`2MSL` 的时间是从**客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 **2MSL 时间将重新计时**。

在 Linux 系统里 `2MSL` 默认是 `60` 秒，那么一个 `MSL` 也就是 `30` 秒。**Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒**。

### 重传机制

`RTT` 指的是**数据发送时刻到接收到确认的时刻的差值**，也就是包的往返时间。

超时重传时间是以 `RTO` （Retransmission Timeout 超时重传时间）表示。

#### 超时重传

在建立连接时，如果连接超时，客户端会发送超时重连的报文段，如果连续5次都没有连接成功，则放弃连接通知应用程序。超时时间在每次发送重连后翻倍，分别为1s、2s、4s、8s、16s。用户在应用程序中可以修改连接超时时间。



#### 快重传

### 流量控制

发送方不能无脑的发数据给接收方，要考虑接收方处理能力。

如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。

为了解决这种现象发生，**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**

#### 窗口关闭

接收方向发送方通告窗口大小时，是通过 `ACK` 报文来通告的。

那么，当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，那麻烦就大了。

这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。

为了解决这个问题，TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**

如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。

如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；

如果接收窗口不是 0，那么死锁的局面就可以被打破了。

窗口探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 `RST` 报文来中断连接。

#### 糊涂窗口综合征



如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。

到最后，**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症**。

**接收方得满足「不通告小窗口给发送方」+ 发送方开启 Nagle 算法，才能避免糊涂窗口综合症**。

另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。

可以在 Socket 设置 `TCP_NODELAY` 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭）

### 拥塞控制

前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。

一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。

**在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大**

所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。

于是，就有了**拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络。**

为了在「发送方」调节所要发送数据的量，定义了一个叫做「**拥塞窗口**」的概念。

#### 慢启动

TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？

慢启动的算法记住一个规则就行：**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**

慢启动算法，发包的个数是**指数性的增长**。

这里假定拥塞窗口 `cwnd` 和发送窗口 `swnd` 相等，下面举个栗子：

1. 连接建立完成后，一开始初始化 `cwnd = 1`，表示可以传一个 `MSS` 大小的数据。
2. 当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个.
3. 当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个.
4. 当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。

有一个叫慢启动门限 `ssthresh` （slow start threshold）状态变量。

当 `cwnd` < `ssthresh` 时，使用慢启动算法。

当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」。

#### 拥塞避免

前面说道，当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法。

一般来说 `ssthresh` 的大小是 `65535` 字节。

那么进入拥塞避免算法后，它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**

接上前面的慢启动的栗子，现假定 `ssthresh` 为 `8`：

当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 `MSS` 大小的数据，变成了**线性增长。**

所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。

就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。

当触发了重传机制，也就进入了「拥塞发生算法」。

#### 拥塞发生

当发生了「超时重传」，则就会使用拥塞发生算法。

这个时候，ssthresh 和 cwnd 的值会发生变化：

`ssthresh` 设为 `cwnd/2`，

`cwnd` 重置为 `1` （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）

接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。

还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd`;
- 进入快速恢复算法

#### 快速恢复

快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 `RTO` 超时那么强烈。

正如前面所说，进入快速恢复之前，`cwnd` 和 `ssthresh` 已被更新了：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd`;

然后，进入快速恢复算法如下：

- 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）；
- 重传丢失的数据包；
- 如果再收到重复的 ACK，那么 cwnd 增加 1；
- 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；

### 粘包问题以及一些解决办法

**原因：**

TCP（Transmission Control Protocol）传输控制协议，是一种面向连接的、可靠的、基于字节流的传输层通信协议。其中跟粘包关系最大的就是基于字节流这个特点。字节流可以理解为一个双向的通道里流淌的数据，这个数据其实就是我们常说的二进制数据，简单来说就是一大堆 01 串。这些 01 串之间没有任何边界。应用层传到 TCP 协议的数据，不是以消息报为单位向目的主机发送，而是以字节流的方式发送，这些数据可能被切割和组装成各种数据包，接收端接收到这些数据包后没有正确还原之前的消息，因此出现粘包现象。不能正确还原主要有两个方面的原因：

**发送端的原因**

发送端在组装消息的时候，就把几个小包合成一包了，这样接收端自然无法解析出小包。这对应的就是Nagle 算法。因为TCP和Nagle 算法都是上个世纪的产物了，在早期的网络中这样做，可以显著地减小网络的压力。否则频繁地发送仅有几个字节的小包，会严重浪费网络IO性能。但是在现代互联网中，网络性能已经有了大幅提升，似乎Nagle 算法提升的那么一点IO性能就不是那么重要了，反而由于等待数据来合并的操作，会导致传输延迟变大，在网络游戏应用时，就会非常影响体验。所以现在一般都会关掉它。

**接收端的原因**

接收端接收到消息以后，应用层总是不能立即取走数据，总是会有接收缓冲区的存在。如果两条独立的消息进入缓冲区的间隔太小，应用层不能在两次消息中间取走上一条消息，那么下次读取的时候，就势必会把两包消息同时读出来，这也会导致粘包。而且这个情况并不能通过让发送端在时间上均匀发包来避免，因为网络不稳定情况的存在，即使是时间上均匀发送的数据包，在接收端看来也可能是随机出现的。

**解决办法：**

1. 加特殊标志作为结束标志，但容易与用户数据中的特殊标志混淆，导致解析错误。

2. 固定包大小，太小导致数据频繁发送，太大会造成资源浪费。

3. 短连接，发送数据时，建立连接，不发送则断开连接，频繁的建立和断开连接也会造成资源浪费。

4. 先发包大小，再发包数据，适用于单线程的场景，两次发送，对应两次接收可以有效解决TCP粘包问题。

5. 然而在多线程场景中，如果先发包大小，再发包数据，可能会出现，先收到两个包大小，又收到两个包数据的情况，此时，接收方会认为第二个包大小就是报数据，导致解析出错。可以通过加锁来将两次发送，两次接收变为原子操作，但这样会导致发送效率降低，加锁解锁的过程中也会增加系统开销。

   **申请sizeof(要发送的数据)+4的空间，先将大小写入堆区，然后再复制要发送的数据，将整体空间通过send发送**，简单来说就是在要发送的数据前面加四个字节，写入该数据包的大小，最后整体发送给到接收端，而接收端的两次接收不需要做任何改动，第一次接收读取前四个字节包的大小，第二次接收读取后面的用户数据部分。

### TCP和UDP的区别

1. 连接

   TCP 是面向连接的传输层协议，传输数据前先要建立连接。

   UDP 是不需要连接，即刻传输数据。

2. 服务对象

   TCPP 是一对一的两点服务，即一条连接只有两个端点。

   UDP 支持一对一、一对多、多对多的交互通信。

3. 可靠性

   TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。

   UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议。

4. 流量控制，拥塞控制

   TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。

   UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

5. 首部开销

   TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。

   UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

6. 传输方式

   TCP 是流式传输，没有边界，但保证顺序和可靠。

   UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。

7. 分片不同

   TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。

   UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

   MSS：除去IP和TCP头，一个网络包所能容纳的TCP数据的最大长度。

   MTU：一个网络包的最大长度，以太网中一般为1500字节。

## HTTP/HTTPS

HTTP 是超文本传输协议，也就是**H**yperText **T**ransfer **P**rotocol。

![ 五大类 HTTP 状态码 ](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png)

### HTTP/1.1 的优点有哪些？

1. 简单

   HTTP 基本的报文格式就是 header + body，头部信息也是 key-value 简单文本的形式，易于理解，降低了学习和使用的门槛。

2. 灵活和易于扩展

   HTTP 协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员自定义和扩充。

   同时 HTTP 由于是工作在应用层（ OSI 第七层），则它下层可以随意变化，比如：

   HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层；

   HTTP/1.1 和 HTTP/2.0 传输协议使用的是 TCP 协议，而到了 HTTP/3.0 传输协议改用了 UDP 协议。

3. 应用广泛和跨平台

   互联网发展至今，HTTP 的应用范围非常的广泛，从台式机的浏览器到手机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应用遍地开花，同时天然具有跨平台的优越性。

### HTTP/1.1 的缺点有哪些？

HTTP 协议里有优缺点一体的双刃剑，分别是「无状态、明文传输」，同时还有一大缺点「不安全」。

1. 无状态双刃剑

无状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。

无状态的坏处，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。

例如登录->添加购物车->下单->结算->支付，这系列操作都要知道用户的身份才行。但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。

这样每操作一次，都要验证信息，这样的购物体验还能愉快吗？别问，问就是酸爽！

对于无状态的问题，解法方案有很多种，其中比较简单的方式用 Cookie 技术。

Cookie 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。

相当于，在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，带上「小贴纸」，服务器就能认得了了，

*2. 明文传输双刃剑*

明文意味着在传输过程中的信息，是可方便阅读的，比如 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。

但是这正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于**信息裸奔**。在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取，如果里面有你的账号密码信息，那**你号没了**。

*3. 不安全*

HTTP 比较严重的缺点就是不安全：

通信使用明文（不加密），内容可能会被窃听。比如，**账号信息容易泄漏，那你号没了。**

不验证通信方的身份，因此有可能遭遇伪装。比如，**访问假的淘宝、拼多多，那你钱没了。**

无法证明报文的完整性，所以有可能已遭篡改。比如，**网页上植入垃圾广告，视觉污染，眼没了。**

HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。

### HTTP和HTTPS的区别

1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。

2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。

3. 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。

4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

### HTTPS 解决了 HTTP 的哪些问题？

HTTP 由于是明文传输，所以安全上存在以下三个风险：

1. 窃听风险，比如通信链路上可以获取通信内容，用户号容易没。

2. 篡改风险，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。
3. 冒充风险，比如冒充淘宝网站，用户钱容易没。

HTTPS 在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议，可以很好的解决了上述的风险：

1. 信息加密：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。

2. 校验机制：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。

3. 身份证书：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。

HTTPS 是如何解决上面的三个风险的？

1. 混合加密的方式实现信息的机密性，解决了窃听的风险。

2. 摘要算法的方式来实现完整性，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。

3. 将服务器公钥放入到数字证书中，解决了冒充的风险。

### HTTPS 是如何建立连接的？其间交互了什么？

SSL/TLS 协议基本流程：

1. 客户端向服务器索要并验证服务器的公钥。

2. 双方协商生产「会话秘钥」。

3. 双方采用「会话秘钥」进行加密通信。

前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。

TLS 的「握手阶段」涉及**四次**通信，使用不同的密钥交换算法，TLS 握手流程也会不一样的，现在常用的密钥交换算法有两种：[RSA 算法 (opens new window)](https://xiaolincoding.com/network/2_http/https_rsa.html)和 [ECDHE 算法 (opens new window)](https://xiaolincoding.com/network/2_http/https_ecdhe.html)。

![image-20230626103714488](C:\Users\zj\AppData\Roaming\Typora\typora-user-images\image-20230626103714488.png)

RSA：服务器拥有成对的公钥和私钥，公钥加密后只有私钥能解开。公钥加密，私钥解密。客户端收到服务器发送的公钥，用公钥给要协商的秘钥进行加密，并且发送出去。服务器拥有与其对应的私钥，因此用私钥解密得到秘钥。
DH：客户端和服务器双方都有私钥，必须提供自己的协商参数给对方，在收到对方的协商参数后，双方用各自的私钥和对方的参数算出同一个秘钥。

RSA+静态和DH+静态在TLS1.3中废除了

DH算法采用了离散对数的算法，反推难度巨大

TLS1.3只支持三种密钥交换模式，

### HTTP1.1、HTTP2、HTTP3 演变

HTTP/1.1 相比 HTTP/1.0 性能上的改进：

1. 使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。

2. 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

但 HTTP/1.1 还是有性能瓶颈：

1. 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 `Body` 的部分；
2. 发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
3. 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；
4. 没有请求优先级控制；
5. 请求只能从客户端开始，服务器只能被动响应。

**HTTP1.1的核心**：默认持久连接，一次一份，如果请求队伍里有一个文件没收到，后面的文件也没法接收了，就造成队头阻塞。

那 HTTP/2 相比 HTTP/1.1 性能上的改进：

1. 头部压缩
2. 二进制格式
3. 并发传输
4. 服务器主动推送资源

**HTTP2的核心**：多路复用

HTTP/3 做了哪些优化？

前面我们知道了 HTTP/1.1 和 HTTP/2 都有队头阻塞的问题：

1. HTTP/1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是**没有解决响应的队头阻塞**，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞。

2. HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是**一旦发生丢包，就会阻塞住所有的 HTTP 请求**，这属于 TCP 层队头阻塞。

HTTP/2 队头阻塞的问题是因为 TCP，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**

UDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题。大家都知道 UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输。

QUIC 有以下 3 个特点。

1. 无队头阻塞

2. 更快的连接建立

3. 连接迁移

   

   